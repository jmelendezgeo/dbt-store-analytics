# ğŸ“Œ Superstore Sales Metrics - dbt Project  

## ğŸ”¹ DescripciÃ³n del Proyecto  
Este proyecto es parte de mi **portafolio de proyectos personales**. Se basa en un **dataset de retail** extraÃ­do de Kaggle y modelado con **dbt**, generando mÃºltiples tablas listas para anÃ¡lisis.  

La arquitectura sigue el diseÃ±o recomendado de **staging, intermediate y marts**, asegurando un flujo de datos estructurado y optimizado.  

## ğŸ”¹ Arquitectura del Proyecto  
El desarrollo se realiza en un **DevContainer**, utilizando **Poetry** para manejar dependencias y **DuckDB** para procesamiento local. La ejecuciÃ³n de `dbt` se gestiona mediante un **Makefile**, simplificando los comandos de transformaciÃ³n de datos.  

ğŸ“‚ **Estructura del Proyecto:**  
```

â”œâ”€â”€ Makefile                        # Comandos de ejecuciÃ³n del proyecto
â”œâ”€â”€ data_processed
â”‚   â””â”€â”€ sales_dataset.parquet       # Dataset original en formato Parquet
â”œâ”€â”€ logs
â”‚   â””â”€â”€ dbt.log                     # Registros de ejecuciÃ³n de dbt
â”œâ”€â”€ poetry.lock                     # Dependencias bloqueadas de Poetry
â”œâ”€â”€ pyproject.toml                   # ConfiguraciÃ³n de Poetry
â””â”€â”€ transform
â”œâ”€â”€ superstore_sales_metrics
â”‚   â”œâ”€â”€ dbt_project.yml          # ConfiguraciÃ³n del proyecto dbt
â”‚   â”œâ”€â”€ models                   # Modelos de transformaciÃ³n de datos
â”‚   â”‚   â”œâ”€â”€ staging
â”‚   â”‚   â”œâ”€â”€ intermediate
â”‚   â”‚   â”œâ”€â”€ marts
â”‚   â”œâ”€â”€ packages.yml             # Dependencias de dbt (dbt-utils, etc.)
â”‚   â”œâ”€â”€ profiles.yml             # ConfiguraciÃ³n de conexiones
â”‚   â”œâ”€â”€ tests                    # Pruebas y validaciones de dbt

```

## ğŸ”¹ InstalaciÃ³n y ConfiguraciÃ³n  

### 1ï¸âƒ£ **Clonar el repositorio**  
```bash
git clone git@github.com:jmelendezgeo/dbt-store-analytics.git
cd superstore_sales_metrics
```

### Definir variables de entorno
Crear un archivo .env con las configuraciones necesarias:

```
SALES_FILE_PATH=data_processed/sales_dataset.parquet  
MOTHERDUCK_TOKEN=<your_token_here>  
```

## EjecuciÃ³n del Proyecto
### ğŸ› ï¸ Ejecutar la transformaciÃ³n de datos en desarrollo local con duckdb 

```bash
make sales-transform
```

Esto ejecutara los siguientes pasos:

- ActivaciÃ³n de entorno con `poetry`
- Instala dependencias de dbt (`dbt deps`)
- Ejecuta los modelos de transformaciÃ³n (`dbt run`)

### Ejecutar en producciÃ³n (MotherDuck)
Para ejecutar el modelo con MotherDuck en la nube, usa:

```bash
make sales-transform DBT_TARGET=prod
```

Esto conectarÃ¡ dbt con MotherDuck, siempre que las credenciales (token) estÃ©n especificadas en .env

## ValidaciÃ³n de Modelos
Este proyecto aplica tests de dbt para asegurar la calidad de los datos:
âœ… not_null en claves primarias (customer_id, order_id, product_id)
âœ… unique en identificadores
âœ… accepted_range en mÃ©tricas financieras (lifetime_value, amount_sales)

Para ejecutar los test usa el comando

```bash
make sales-test
```

Esto ejecutara los siguientes pasos:

- ActivaciÃ³n de entorno con `poetry`
- Instala dependencias de dbt (`dbt deps`)
- Ejecuta los test de los modelos (`dbt test`)

## DocumentaciÃ³n de Modelos
Los modelos estÃ¡n documentados con dbt docs, siguiendo una estructura clara:
- staging: Tablas crudas procesadas.
- intermediate: Transformaciones intermedias.
- marts: Tablas finales optimizadas para anÃ¡lisis.
Para generar la documentaciÃ³n:

```bash
make sales-docs-generate
```

Esto ejecutara los siguientes pasos:

- ActivaciÃ³n de entorno con `poetry`
- Instala dependencias de dbt (`dbt deps`)
- GeneraciÃ³n de documentaciÃ³n (`dbt docs generate`)
- Deploy de documentaciÃ³n en localhost puerto 8080 (`dbt docs serve`)

